{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.17"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Optimizing Baseline Cuts\n",
    "\n",
    "Optimizing the baseline cuts and checking the results on two parameters :\n",
    "- Percent of Events that Survive\n",
    "- Accuracy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Welcome to JupyROOT 6.24/00\n"
     ]
    }
   ],
   "source": [
    "import ROOT\n",
    "from ROOT import TLorentzVector\n",
    "from math import sqrt\n",
    "import h5py\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "source": [
    "## Getting Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArraysFromFile(inputFile : str, debug = True):\n",
    "    '''\n",
    "    Accessor function that gives back lists from hdf5 file. Due to the various conversions from \n",
    "    List --> Awkward --> HDF5 file, this function is made as to make the conversion back to list \n",
    "    simple.\n",
    "    Parameters :\n",
    "    ------------\n",
    "    inputFile : str, required\n",
    "        The hdf5 file with the converted list\n",
    "    Returns :\n",
    "    ---------\n",
    "    particleArray : list\n",
    "        The list that contains the 4-momenta of every particle in every event.\n",
    "    azArray : list\n",
    "        The list that contains the azimuthal angle of every particle in every event.\n",
    "    '''\n",
    "    if debug:\n",
    "        print(\"INFO : Started Getting Data From File\")\n",
    "\n",
    "    hf = h5py.File(inputFile,'r')\n",
    "    partArray = hf.get(\"ParticleArray\")\n",
    "    azimuthalArray = hf.get(\"AzimuthalAngle\")\n",
    "    etaArray = hf.get(\"EtaAngle\")\n",
    "    phiArray = hf.get(\"PhiAngle\")\n",
    "\n",
    "    reconstitutedPartArray = ak.from_buffers(\n",
    "        ak.forms.Form.fromjson(partArray.attrs[\"form\"]),\n",
    "        json.loads(partArray.attrs[\"length\"]),\n",
    "        {k: np.asarray(v) for k, v in partArray.items()},\n",
    "    )\n",
    "\n",
    "    reconstitutedAzAngle = ak.from_buffers(\n",
    "        ak.forms.Form.fromjson(azimuthalArray.attrs[\"form\"]),\n",
    "        json.loads(azimuthalArray.attrs[\"length\"]),\n",
    "        {k: np.asarray(v) for k, v in azimuthalArray.items()},\n",
    "    )\n",
    "\n",
    "    reconstitutedEtaAngle = ak.from_buffers(\n",
    "        ak.forms.Form.fromjson(etaArray.attrs[\"form\"]),\n",
    "        json.loads(etaArray.attrs[\"length\"]),\n",
    "        {k: np.asarray(v) for k, v in etaArray.items()},\n",
    "    )\n",
    "\n",
    "    reconstitutedPhiAngle = ak.from_buffers(\n",
    "        ak.forms.Form.fromjson(phiArray.attrs[\"form\"]),\n",
    "        json.loads(phiArray.attrs[\"length\"]),\n",
    "        {k: np.asarray(v) for k, v in phiArray.items()},\n",
    "    )\n",
    "    \n",
    "    particleArray = ak.to_list(reconstitutedPartArray)\n",
    "    azArray = ak.to_list(reconstitutedAzAngle)\n",
    "    etaArray = ak.to_list(reconstitutedEtaAngle)\n",
    "    phiArray = ak.to_list(reconstitutedPhiAngle)\n",
    "\n",
    "    if debug:\n",
    "        print(\"INFO : Done Getting Data from File\")\n",
    "    return particleArray,azArray,etaArray,phiArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyperparameters\n",
    "\n",
    "process  = ['ttbar','llbj','tWj','ttV','ttbarh','taubb','hh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO : The number of particles in each datasets are 10000\n",
      "INFO : The number of particles in each datasets are 50000\n",
      "INFO : The number of particles in each datasets are 10000\n",
      "INFO : The number of particles in each datasets are 10000\n",
      "INFO : The number of particles in each datasets are 10000\n",
      "INFO : The number of particles in each datasets are 10000\n",
      "INFO : The number of particles in each datasets are 10000\n"
     ]
    }
   ],
   "source": [
    "part = []\n",
    "angle = []\n",
    "for proc in process:\n",
    "    part_temp,angle_temp,_,_ = getArraysFromFile('../../datasets/partonCuts/' + proc + '_10k.h5',debug=False)\n",
    "    part.append(part_temp)\n",
    "    angle.append(angle_temp)\n",
    "    print('INFO : The number of particles in each datasets are ' + str(len(part_temp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in part:\n",
    "    for j in i:\n",
    "        if len(j) > max_len:\n",
    "            max_len = len(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_array = [0]*7\n",
    "fin_array = part\n",
    "for i in range(len(part)):\n",
    "    for j in range(len(part[i])):\n",
    "        #print(j)\n",
    "        for l in range(max_len - len(part[i][j])):\n",
    "           fin_array[i][j].append(buffer_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(len(fin_array) - 1):\n",
    "    for j in range(len(fin_array[i])):\n",
    "        x_train.append(fin_array[i][j])\n",
    "        y_train.append(0)\n",
    "\n",
    "for j in range(len(fin_array[-1])):\n",
    "    x_train.append(fin_array[-1][j])\n",
    "    y_train.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(110000, 17, 7)"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "x_train.shape"
   ]
  }
 ]
}